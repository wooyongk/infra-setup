x-airflow-common: &airflow-common
  image: ${AZURE_REGISTRY}/infra/airflow:latest
  environment:
    # Core settings
    AIRFLOW__CORE__EXECUTOR: LocalExecutor
    AIRFLOW__CORE__FERNET_KEY: ${AIRFLOW__CORE__FERNET_KEY}
    AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION: True
    AIRFLOW__CORE__LOAD_EXAMPLES: False
    AIRFLOW__CORE__DEFAULT_TIMEZONE: "Asia/Seoul"
    AIRFLOW__CORE__ENABLE_XCOM_PICKLING: True
    AIRFLOW__CORE__SQL_ALCHEMY_CONN: ${AIRFLOW__DATABASE__SQL_ALCHEMY_CONN}

    # API settings
    AIRFLOW__API__AUTH_BACKENDS: "airflow.api.auth.backend.basic_auth,airflow.api.auth.backend.session"

    # Scheduler settings
    AIRFLOW__SCHEDULER__ENABLE_HEALTH_CHECK: True
    AIRFLOW__SCHEDULER__STATSD_HOST: "statsd-exporter"

    # Webserver settings
    AIRFLOW__WEBSERVER__DEFAULT_UI_TIMEZONE: "Asia/Seoul"
    AIRFLOW__WEBSERVER__SECRET_KEY: ${AIRFLOW__WEBSERVER__SECRET_KEY}
    AIRFLOW__WEBSERVER__WARN_DEPLOYMENT_EXPOSURE: False

    # Logging settings
    AIRFLOW__LOGGING__REMOTE_LOGGING: True
    AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID: "R2"
    AIRFLOW__LOGGING__REMOTE_BASE_LOG_FOLDER: "s3://${R2_FOLDER}/logs"
    AIRFLOW__LOGGING__DELETE_LOCAL_LOGS: True

    # Metrics settings
    AIRFLOW__METRICS__STATSD_ON: True

    # Common IO
    AIRFLOW__COMMON_IO__XCOM_OBJECTSTORAGE_PATH: s3://R2@{R2_FOLDER}/xcom
    AIRFLOW__COMMON_IO__XCOM_OBJECTSTORAGE_THRESHOLD: 104857
    AIRFLOW__COMMON_IO__XCOM_OBJECTSTORAGE_COMPRESSION: gzip

    # Connection settings
    AIRFLOW_CONN_R2: '{
      "conn_type": "aws",
      "login": "${R2_ACCESS_KEY}",
      "password": "${R2_SECRET_ACCESS_KEY}",
      "extra": {"service_config": {"s3": {"endpoint_url": "${R2_ENDPOINT_URL}"}}}
    }'

  volumes:
    - airflow-dags-volume:/opt/airflow/dags
    - airflow-logs-volume:/opt/airflow/logs
  user: "${AIRFLOW_UID:-50000}:0"

  logging:
    driver: "loki"
    options:
      loki-url: ${LOG_LOKI_URL}

services:
  airflow-webserver:
    <<: *airflow-common
    container_name: airflow-webserver
    command: webserver
    ports:
      - "8080:8080"
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8080/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          memory: 6G

  airflow-scheduler:
    <<: *airflow-common
    container_name: airflow-scheduler
    command: scheduler
    healthcheck:
      test: ["CMD", "curl", "--fail", "http://localhost:8974/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    restart: always
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    deploy:
      resources:
        limits:
          memory: 4G

  airflow-init:
    <<: *airflow-common
    container_name: airflow-init
    entrypoint: /bin/bash
    command:
      - -c
      - airflow db migrate &&
        airflow users create
        --role Admin
        --username ${AIRFLOW_USER_USERNAME}
        --password ${AIRFLOW_USER_PASSWORD}
        --email airflow@airflow.com
        --firstname wooyong
        --lastname kim

  statsd-exporter:
    image: prom/statsd-exporter
    container_name: airflow-statsd-exporter
    command: "--statsd.listen-udp=:8125 --web.listen-address=:9102"
    ports:
      - 9123:9102
      - 8125:8125/udp

  git-sync:
    image: databurst/git-sync:latest
    container_name: git-sync
    environment:
      REPO_URL: https://github.com/wooyongk/data-engineering-project.git
      GIT_BRANCH: main
      DIRECTORY_NAME: project
      DESTINATION_PATH: /app/sync
      SUBFOLDER_PATH: /airflow/dags
      INTERVAL: 10
    volumes:
      - airflow-dags-volume:/app/sync/dags
    depends_on:
      airflow-init:
        condition: service_completed_successfully
    logging:
      driver: "loki"
      options:
        loki-url: ${LOG_LOKI_URL}

  cadvisor:
    image: gcr.io/cadvisor/cadvisor:latest
    container_name: cadvisor
    ports:
      - "9999:8080"
    volumes:
      - /:/rootfs:ro
      - /var/run:/var/run:rw
      - /sys:/sys:ro
      - /var/lib/docker/:/var/lib/docker:ro

volumes:
  airflow-dags-volume:
  airflow-logs-volume:
